# 🎓 机器学习面试 Hashcards

> 按照 hashcards 格式设计，使用 `Q:` 和 `A:` 标记问答，`[关键词]` 用于挖空记忆

---

## 一、逻辑回归 (Logistic Regression)

### 1.1 基础概念

Q: 逻辑回归的本质是什么？
A: 逻辑回归的本质是[极大似然估计]，通过 Sigmoid 函数将线性回归的输出映射到 (0,1) 区间，表示样本属于正类的概率。

Q: 逻辑回归使用什么激活函数？其数学表达式是什么？
A: 使用 [Sigmoid] 函数（对数几率函数）：$\sigma(z) = \frac{1}{1+e^{-z}}$，将输出限制在 [0,1] 区间。

Q: 逻辑回归使用什么损失函数？为什么？
A: 使用[交叉熵]损失函数：$J = -\sum[y\log(\hat{y}) + (1-y)\log(1-\hat{y})]$。因为平方损失在 Sigmoid 下是非凸的，而交叉熵是凸函数，便于优化。

Q: 为什么 LR 要使用 Sigmoid 函数？（三个原因）
A: ①广义线性模型推导所得；②满足统计的[最大熵模型]；③性质优秀：平滑、任意阶可导，一阶二阶导数可由函数值直接得到。

Q: 逻辑回归的优缺点？
A: 优点：①速度快，适合[二分类]；②简单易解释，可看特征权重；③易于增量学习。缺点：对数据和场景适应能力有限，不如决策树灵活。

### 1.2 进阶问题

Q: LR 能否解决非线性分类问题？
A: 原始 LR 是线性分类器，但可通过[特征工程]（多项式特征、交叉特征）或[核技巧]扩展到非线性问题。

Q: LR 为什么经常对特征做离散化？
A: ①增强[鲁棒性]，减少异常值影响；②引入非线性；③加速计算；④便于特征交叉；⑤稀疏化存储。

Q: LR 可以用核函数吗？为什么通常不用？
A: 可以，但计算复杂度高。LR 需要计算所有样本的概率，核化后复杂度为 $O(n^2)$，而 [SVM] 只需计算支持向量。

---

## 二、支持向量机 (SVM)

### 2.1 基础原理

Q: SVM 的核心思想是什么？
A: [间隔最大化]——在特征空间中寻找一个分离超平面，使得两类样本到超平面的最小几何间隔最大，这样的分类器泛化能力最强。

Q: SVM 的三种形式分别针对什么情况？
A: ①[硬间隔] SVM：线性可分数据；②[软间隔] SVM：近似线性可分（引入松弛变量）；③[核] SVM：非线性数据（核技巧映射到高维）。

Q: 什么是支持向量？
A: 距离分离超平面最近的那些样本点，它们[唯一确定]分离超平面。最终决策函数只依赖于支持向量，与其他样本无关。

Q: 为什么 SVM 要转化为对偶问题求解？
A: ①对偶问题更易求解（约束更少）；②自然引入[核函数]，便于推广到非线性；③便于利用 SMO 等高效算法。

### 2.2 核函数

Q: 常用的 SVM 核函数有哪些？
A: ①[线性核]：$K(x,y)=x^Ty$；②[多项式核]：$(x^Ty+c)^d$；③[RBF/高斯核]：$\exp(-\gamma\|x-y\|^2)$；④Sigmoid 核；⑤拉普拉斯核。

Q: 如何选择核函数？
A: ①特征维度高、样本少→[线性核]或 LR；②特征少、样本中等→[RBF 核]（需调参 $\gamma$）；③RBF 是通用选择，但计算开销大。

Q: 核技巧的本质是什么？
A: 在高维空间中计算内积，无需显式计算映射。只要函数 $K(x,y)$ 满足 [Mercer 条件]（半正定），就存在对应的特征映射。

### 2.3 LR vs SVM

Q: LR 和 SVM 的相同点？
A: ①都是[判别模型]；②都是[线性分类器]（不考虑核）；③都是监督学习；④都可用于分类任务。

Q: LR 和 SVM 的主要区别？
A: ①损失函数不同：LR 用[交叉熵]，SVM 用 [Hinge Loss]；②SVM 只关注支持向量，LR 用所有样本；③SVM 有结构风险最小化，LR 需显式加正则。

---

## 三、决策树与集成学习

### 3.1 决策树基础

Q: 决策树如何选择最优划分特征？
A: ①ID3：[信息增益]（偏向多值特征）；②C4.5：[信息增益率]；③CART：[基尼指数]。

Q: 信息增益的定义是什么？
A: $Gain(D,a) = Ent(D) - \sum_{v}\frac{|D_v|}{|D|}Ent(D_v)$，即划分前后[信息熵]的减少量。

Q: 基尼指数的定义和含义？
A: $Gini(D) = 1 - \sum_{k}p_k^2$，表示从数据集中随机抽取两个样本类别[不一致]的概率，越小纯度越高。

Q: 决策树如何防止过拟合？
A: ①[预剪枝]：提前停止生长（限制深度、叶子样本数）；②[后剪枝]：先生成完整树再自底向上剪枝（如 CART 的代价复杂度剪枝）。

### 3.2 集成学习

Q: Bagging 和 Boosting 的核心区别？
A: [Bagging]：并行训练，[有放回采样]，基学习器独立，降低方差（如 Random Forest）。[Boosting]：串行训练，样本加权，基学习器相关，降低偏差（如 AdaBoost、GBDT）。

Q: 随机森林的"随机"体现在哪？
A: ①样本随机：[Bootstrap 采样]；②特征随机：每次分裂随机选择 $\sqrt{d}$ 或 $\log_2 d$ 个特征。

Q: GBDT 的基本原理？
A: [梯度提升]框架，每轮拟合前一轮残差（负梯度方向），基学习器是 [CART 回归树]。最终预测为所有树的加权和。

Q: XGBoost 相比 GBDT 的改进？
A: ①损失函数加入[二阶导数]；②正则化（叶子数+权重 L2）；③支持列抽样；④缺失值处理；⑤并行化特征分裂点搜索。

---

## 四、聚类算法

### 4.1 K-Means

Q: K-Means 的算法流程？
A: ①随机初始化 K 个[质心]；②分配：每个样本归入最近质心的簇；③更新：重新计算各簇质心；④重复②③直到质心不变或达到迭代次数。

Q: K-Means 的缺点？
A: ①需预设 [K 值]；②对[初始化]敏感；③只能发现凸形簇；④对异常值敏感；⑤假设簇大小相近。

Q: 如何选择 K 值？
A: ①[肘部法则]：绘制 SSE-K 曲线，找拐点；②[轮廓系数]：综合簇内紧密度和簇间分离度；③业务先验。

### 4.2 其他聚类

Q: DBSCAN 的核心思想？
A: 基于[密度]的聚类，由核心点（ε邻域内至少有 MinPts 个点）出发，扩展密度可达的点形成簇。能发现任意形状簇，自动识别噪声。

Q: 层次聚类的两种方式？
A: ①[凝聚式]（自底向上）：每个样本初始为一簇，逐步合并；②[分裂式]（自顶向下）：所有样本初始为一簇，逐步分裂。

---

## 五、降维与特征工程

### 5.1 PCA

Q: PCA 的核心思想？
A: 寻找[方差最大]的投影方向（主成分），实现降维。数学上是对协方差矩阵做特征分解，取最大特征值对应的特征向量。

Q: PCA 的步骤？
A: ①数据[中心化]；②计算协方差矩阵；③特征分解；④选取前 k 个[最大特征值]对应的特征向量；⑤投影降维。

Q: PCA 和 LDA 的区别？
A: [PCA]：无监督，最大化投影方差；[LDA]：有监督，最大化类间散度/类内散度，即找到最有利于分类的投影方向。

### 5.2 特征工程

Q: 为什么要做特征归一化？
A: ①消除量纲影响；②加速[梯度下降]收敛；③对距离敏感的算法（KNN、SVM、K-Means）很重要。

Q: 常用的归一化方法？
A: ①[Min-Max]：$(x-min)/(max-min)$，映射到 [0,1]；②[Z-Score]：$(x-\mu)/\sigma$，均值0方差1；③L2 归一化。

Q: 如何处理类别特征？
A: ①[One-Hot]：转为二进制向量（高基数特征慎用）；②[Label Encoding]：简单编码为整数；③[Target Encoding]：用类别均值替代。

---

## 六、模型评估

### 6.1 分类指标

Q: 混淆矩阵的四个元素？
A: [TP]：真正例；[FP]：假正例（误报）；[FN]：假负例（漏报）；[TN]：真负例。

Q: Precision 和 Recall 的定义？
A: [Precision] = TP/(TP+FP)，预测为正中真正为正的比例。[Recall] = TP/(TP+FN)，实际为正中被正确预测的比例。

Q: F1-Score 的定义和意义？
A: $F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}$，是 P 和 R 的[调和平均]，平衡两者的综合指标。

Q: ROC 曲线和 AUC 的含义？
A: [ROC]：以 FPR 为横轴、TPR 为纵轴的曲线。[AUC]：ROC 下面积，表示随机正样本得分高于随机负样本的概率，越大越好。

Q: 什么情况下用 PR 曲线而非 ROC？
A: [样本不均衡]时。ROC 对负样本数量不敏感，而 PR 曲线更能反映正类的预测效果。

### 6.2 回归指标

Q: 常用的回归评估指标？
A: ①[MSE]：均方误差；②[RMSE]：均方根误差；③[MAE]：平均绝对误差；④[R²]：决定系数，衡量拟合优度。

---

## 七、正则化与过拟合

### 7.1 正则化

Q: L1 和 L2 正则化的区别？
A: [L1]：权重绝对值之和，产生[稀疏]解（特征选择）。[L2]：权重平方和，使权重[趋近于0]但不为0，防止过拟合。

Q: 为什么 L1 会产生稀疏解？
A: 几何解释：L1 约束是菱形，损失函数等高线更可能在[顶点]相切，顶点处某些权重为0。

Q: Lasso 和 Ridge 回归分别对应什么正则化？
A: [Lasso]：L1 正则化；[Ridge]：L2 正则化；[Elastic Net]：L1+L2 组合。

### 7.2 过拟合与欠拟合

Q: 什么是过拟合和欠拟合？
A: [过拟合]：训练误差小、测试误差大（高方差）。[欠拟合]：训练和测试误差都大（高偏差）。

Q: 防止过拟合的方法？
A: ①增加数据/[数据增强]；②[正则化]（L1/L2）；③[Dropout]；④[Early Stopping]；⑤简化模型；⑥集成方法。

Q: 解决欠拟合的方法？
A: ①增加特征/[多项式特征]；②减少正则化；③使用更复杂的模型；④增加训练时间。

---

## 八、其他重要概念

### 8.1 偏差-方差权衡

Q: 什么是偏差-方差分解？
A: 泛化误差 = [Bias²] + [Variance] + Noise。偏差：模型预测均值与真实值的差距。方差：不同训练集上预测的波动。

Q: 如何理解偏差-方差权衡？
A: 模型越复杂，偏差↓方差↑；模型越简单，偏差↑方差↓。需要找到[平衡点]使总误差最小。

### 8.2 交叉验证

Q: K 折交叉验证的流程？
A: 将数据分成 K 份，每次用 [K-1 份]训练、1 份验证，重复 K 次，取平均性能作为模型评估。

Q: 为什么要用交叉验证？
A: ①更充分利用数据；②减少因划分不同带来的[方差]；③得到更可靠的性能估计。

### 8.3 样本不均衡

Q: 处理样本不均衡的方法？
A: ①[过采样]：SMOTE 等合成少数类；②[欠采样]：减少多数类；③[代价敏感]学习；④调整阈值；⑤集成方法（如 EasyEnsemble）。

---

## 九、距离度量

Q: 常用的距离度量方法？
A: ①[欧氏距离]：$\sqrt{\sum(x_i-y_i)^2}$；②[曼哈顿距离]：$\sum|x_i-y_i|$；③[余弦相似度]；④[马氏距离]；⑤汉明距离。

Q: 余弦相似度和欧氏距离的区别？
A: [余弦相似度]衡量方向，对向量长度不敏感，适合文本；[欧氏距离]衡量绝对距离，对量纲敏感。

---

## 十、概率图模型

### 10.1 朴素贝叶斯

Q: 朴素贝叶斯的核心假设？
A: [条件独立性]假设：给定类别，各特征之间相互独立。即 $P(X|Y) = \prod P(x_i|Y)$。

Q: 朴素贝叶斯的分类公式？
A: $\hat{y} = \arg\max_y P(y)\prod_{i}P(x_i|y)$，选择[后验概率]最大的类别。

### 10.2 隐马尔可夫模型

Q: HMM 的三个基本问题？
A: ①[概率计算]：前向-后向算法；②[学习问题]：Baum-Welch（EM）或监督学习；③[解码问题]：Viterbi 算法。

Q: HMM 的五元组？
A: $\lambda = (\pi, A, B, S, O)$：[初始概率]、[转移概率]、[发射概率]、隐状态集、观测集。

---

*Generated by hashcards format for spaced repetition learning*